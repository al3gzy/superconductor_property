# Superconductor Property Prediction  

## ðŸ“Œ Overview  
Superconductors are materials that can conduct electricity without resistance at low temperatures, and finding materials that exhibit superconductivity at higher temperatures is a significant challenge. The property of superconductors enables significant technological advancements in power grids (lossless power transmission over long distances), magnetic levitation (high-speed transportation with minimal energy consumption) and medical imaging. By incorporating ML methods, we can predict the superconducting properties of materials based on their atomic structure and composition, accelerating the whole discovery process. Therefore, this project aim is to provide information about new high-temperature superconducting materials.

## Features  
Models we will use are **Linear Regression**, **Random Forest**, and **Gradient Boosting** due to their complementary strengths in handling regression problems. Linear Regression serves as a simple and interpretable baseline model, assuming a linear relationship between the features and the target variable (Tc). It helps us evaluate whether a straightforward approach can capture the relationship in our data. Random Forest, on the other hand, is a robust ensemble method that handles non-linear relationships and interactions between features. It is less prone to overfitting compared to individual decision trees, making it effective in capturing complex interactions. Lastly, Gradient Boosting is a powerful ensemble technique that builds trees sequentially to correct errors made by previous models, often achieving better performance due to its iterative error minimization. By comparing these models, we aim to identify the best approach for predicting superconducting temperatures (Tc) while balancing simplicity, robustness, and predictive accuracy.

## Results
The model evaluations indicate that Random Forest is the most effective, achieving an MSE of 78.74 and an RÂ² of 0.93, which are the lowest error and highest explanatory power among the models tested. Gradient Boosting also performs well with an MSE of 161.57 and an RÂ² of 0.85, surpassing Linear Regression, which has an MSE of 305.32 and an RÂ² of 0.73. These results suggest that Random Forest provides the best balance of accuracy and explanatory power in this analysis.
